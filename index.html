<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>
    Real-Time 3D Pedestrian Simulation from 2D Trajectories
  </title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f4f4f4;
      color: #333;
      max-width: 900px;
      margin: auto;
      padding: 2em;
    }
    h1, h2 {
      color: #2c3e50;
    }
    .gif-container {
      text-align: center;
      margin: 2em 0;
    }
    .tech-list, .dataset-list {
      list-style-type: square;
      margin-left: 2em;
    }
    a {
      color: #007acc;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    .citation {
      font-style: italic;
      font-size: 0.95em;
    }
  </style>
</head>
<body>
  <p><a href="https://amartaivan-s.github.io/">ğŸ  Home</a></p>
  <h1>Reconstructing Real-Time 3D Pedestrian Motion from 2D Trajectories</h1>
  <h2 style="color:#555; font-weight:normal;">
    Reconstructing Movement in 3D Space Using Multi-Pedestrian Tracking Data and Interactive 3D Rendering
  </h2>

    <h2>ğŸ” Project Overview</h2>
  <p>
    This project provides a <strong>real-time 3D visualization</strong> of real-world multi-pedestrian trajectories, transforming 2D tracking data into an interactive 3D representation. Unlike static plots, it uses <strong>PyQtGraphâ€™s OpenGL module</strong> to render pedestrians as <strong>customizable humanoid models</strong>, with individually modeled body partsâ€”head, torso, arms, and legsâ€”allowing realistic depiction of posture and motion.  
  </p>
  <p>
    The visualization incorporates <strong>environmental geometry</strong>, including walls, exits, and pillars, to accurately reflect the spatial context of the original environment. Pedestrians move through this 3D scene in real-time according to recorded trajectories, enabling interactive exploration such as rotating the viewpoint, zooming, and inspecting individual agents.  
  </p>
  <p>
    This setup supports detailed analysis of <strong>crowd behavior, space usage, and human-environment interactions</strong> without relying on predictive simulation models, providing a clear and immersive way to study pedestrian movement in existing environments.
  </p>

  
<div class="gif-container" style="max-width: 800px; margin: 2em auto;">
  <video autoplay muted loop playsinline style="width: 100%; height: auto; border-radius: 6px; box-shadow: 0 4px 12px rgba(0,0,0,0.2);">
    <source src="3d-pedestrians.mp4" type="video/mp4">
    Your browser does not support the video tag.
  </video>
  <p><small>Figure: Sample 3D simulation of pedestrians with custom humanoid models in an environment.</small></p>
</div>


  <h2>ğŸ§° Technologies Used</h2>
  <ul class="tech-list">
     <li>
    <strong>Python</strong> â€“ core logic, data loading, and agent control
  </li>
  <li>
    <a href="https://www.pyqtgraph.org/" target="_blank"><strong>PyQtGraph</strong></a> â€“ 2D/3D plotting and OpenGL-based visualization
    (<a href="https://pyqtgraph.readthedocs.io/en/latest/getting_started/3dgraphics.html" target="_blank">3D Graphics Docs</a>)
  </li>
  </ul>

  <h2>ğŸ“¦ Dataset</h2>
  <ul class="dataset-list">
    <li>
      <a href="https://dil.atr.jp/ISL/crest2010_HRI/ATC_dataset/" target="_blank">
        ATC Pedestrian Trajectory Dataset
      </a> â€“ Real-world shopping mall pedestrian trajectories collected by ATC, Japan
    </li>
  </ul>
  <p class="citation">
    D. Brscic, T. Kanda, T. Ikeda, T. Miyashita, "Person position and body direction tracking in large public spaces using 3D range sensors", IEEE Transactions on Human-Machine Systems, Vol. 43, No. 6, pp. 522-534, 2013
  </p>

  <h2>ğŸ¯ Goals & Applications</h2>
  <ul class="tech-list">
    <li>Model and reproduce realistic pedestrian behaviors in 3D space</li>
    <li>Render interactive humanoid agents using PyQtGraph OpenGL</li>
    <li>Analyze spatial interactions and crowd density in real environments</li>
    <li>Support research on evacuation modeling, AI behavior, and space optimization</li>
  </ul>

  <h2>ğŸš§ Current Status</h2>
  <p>
    âœ”ï¸ Customized 3D humanoid agents created (body, head, arms, legs)<br/>
    âœ”ï¸ Real-time trajectory playback using PyQtGraph OpenGL 3D<br/>
    ğŸ”„ Implementing environment import, collision detection, and user interaction controls<br/>
    ğŸ“ˆ Planning to integrate statistical analysis tools

<footer style="margin-top: 3em; font-size: 0.85em; color: #666;">
    Last updated: Oct 2025 â€¢ Author: Sanjjamts Amartaivan
  </footer>

  </body>
</html>
